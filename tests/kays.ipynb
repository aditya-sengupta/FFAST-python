{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipdb\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_signal(w, theta, n, skip=1, shift=0):\n",
    "    \"\"\"\n",
    "    Assumes normalized amplitude\n",
    "    \"\"\"\n",
    "    t = np.arange(shift,shift+n*skip,skip)\n",
    "    signal = np.exp(1j*(w*t + theta))\n",
    "    return signal\n",
    "\n",
    "def make_noise(sigma2,n):\n",
    "    noise_scaling = np.sqrt(sigma2/2)\n",
    "    # noise is complex valued\n",
    "    noise  = noise_scaling*np.random.randn(n) + 1j*noise_scaling*np.random.randn(n)\n",
    "    return noise\n",
    "\n",
    "def make_noisy_signal(w, theta, sigma2, n, skip=1):\n",
    "    \"\"\"\n",
    "    w: frequency in radians per sample\n",
    "    theta: phase\n",
    "    sigma2: noise variance\n",
    "    n: number of samples\n",
    "    skip: sampling period\n",
    "    \"\"\"\n",
    "    signal = make_signal(w,theta,n,skip)\n",
    "    noise  = make_noise(sigma2,n)\n",
    "    return signal + noise\n",
    "\n",
    "def get_sigma2_from_snrdb(SNR_db):\n",
    "    return 10**(-SNR_db/10)\n",
    "\n",
    "def kay_weights(N):\n",
    "    scaling = 6.0/N/(N**2 - 1)\n",
    "    w = [(N-i-1)*(i+1) for i in range(N-1)]\n",
    "    return scaling*np.array(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kay's methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kays_method1(my_signal, simple_average=False):\n",
    "    \"\"\"\n",
    "    This is the implementation in the paper\n",
    "    \"\"\"\n",
    "    N = len(my_signal)\n",
    "\n",
    "    if simple_average:\n",
    "        w = np.ones_like(w)\n",
    "    else:\n",
    "        w = kay_weights(N)\n",
    "        \n",
    "    angle_diff = np.angle(np.conj(my_signal[0:-1])*my_signal[1:])\n",
    "#     ipdb.set_trace()\n",
    "    need_to_shift = np.any(angle_diff < -np.pi/2)\n",
    "    \n",
    "    omega = w.dot(angle_diff)\n",
    "    \n",
    "    if need_to_shift:   \n",
    "#         print('needed to shift')\n",
    "        neg_idx = angle_diff < 0\n",
    "        omega += np.sum(w[neg_idx]*np.pi*2)\n",
    "    \n",
    "    return omega\n",
    "\n",
    "def kays_method2(my_signal, simple_average=False):\n",
    "    \"\"\"\n",
    "    This is my best implementation\n",
    "    \"\"\"\n",
    "    N = len(my_signal)\n",
    "        \n",
    "    if not simple_average:\n",
    "        w = kay_weights(N)\n",
    "    else:\n",
    "        w = np.ones_like(w)\n",
    "        \n",
    "    # we will check 4 settings\n",
    "    t = np.arange(N)\n",
    "    \n",
    "    v_best = -np.inf\n",
    "    omega_best = 0\n",
    "    for k in range(4):\n",
    "        rotater = np.exp(-1j*np.pi*k*t/2)\n",
    "        y = my_signal*rotater\n",
    "        angle_diff = np.angle(np.conj(y[0:-1])*y[1:])\n",
    "        omega = w.dot(angle_diff)\n",
    "        \n",
    "        y_hat = np.exp(1j*omega*t)\n",
    "        \n",
    "        v = np.abs(np.dot(y, np.conj(y_hat)))\n",
    "        if v > v_best:\n",
    "            omega_best = (omega + k*np.pi/2) % (2*np.pi)\n",
    "            v_best = v\n",
    "    \n",
    "    return omega_best\n",
    "\n",
    "def kays_method3(my_signal, simple_average=False):\n",
    "    \"\"\"\n",
    "    This is somewhere in between\n",
    "    \"\"\"\n",
    "    N = len(my_signal)\n",
    "\n",
    "    if simple_average:\n",
    "        w = np.ones_like(w)\n",
    "    else:\n",
    "        w = kay_weights(N)\n",
    "        \n",
    "    angle_diff = np.angle(np.conj(my_signal[0:-1])*my_signal[1:])\n",
    "    \n",
    "    rhs = ((angle_diff + np.pi/2) > 0) & ((angle_diff + np.pi/2) < np.pi)\n",
    "    if np.mean(rhs) > 0.5:\n",
    "        need_to_shift = False\n",
    "    else:\n",
    "        need_to_shift = True\n",
    "    \n",
    "#     need_to_shift = np.any(angle_diff < -np.pi/2)\n",
    "    \n",
    "    omega = w.dot(angle_diff)\n",
    "    \n",
    "    if need_to_shift:   \n",
    "        neg_idx = angle_diff < 0\n",
    "        omega += np.sum(w[neg_idx]*np.pi*2)\n",
    "    \n",
    "    return omega\n",
    "\n",
    "kays_method = kays_method2\n",
    "\n",
    "def successive_estimation(signal_chain, N, p=2, rounding=None):\n",
    "    location_bis = 0\n",
    "    num_chains = len(signal_chain)\n",
    "    # from radians to location\n",
    "    factor = N/(2*np.pi)\n",
    "    # how many frequencies wrap to the location\n",
    "    nwrap = 1\n",
    "    \n",
    "    for chain in signal_chain:\n",
    "        temp_location = (kays_method(chain)*factor) %  N\n",
    "        loc_update = temp_location/nwrap - location_bis\n",
    "        r = loc_update - round((loc_update * nwrap)/N)*N/nwrap\n",
    "        location_bis += r\n",
    "        nwrap *= p\n",
    "    location = round(location_bis) % N\n",
    "    \n",
    "    if rounding is not None:\n",
    "        bin_relative_index, F = rounding\n",
    "        location = (round((location_bis - bin_relative_index)/F)*F + bin_relative_index) % N\n",
    "        \n",
    "    return location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16\n",
    "f0 = 2\n",
    "w0 = (2*np.pi)*f0/N % (2*np.pi)\n",
    "\n",
    "\n",
    "my_signal = make_signal(w0,0,N)\n",
    "my_signal_fft = np.fft.fft(my_signal)\n",
    "\n",
    "plt.stem(np.abs(my_signal_fft))\n",
    "plt.title('w: {}'.format(w0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omega_to_location(w,N):\n",
    "    return w*(N/(2*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_to_location(kays_method(my_signal),N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_successive_estimation_sampling_chains(num_chains, \n",
    "                                               num_samples_per_chain, \n",
    "                                               N, \n",
    "                                               p=2, \n",
    "                                               random_start=False):\n",
    "    \"\"\"\n",
    "    This function makes sampling points for successive estimation method\n",
    "    \"\"\"\n",
    "    chains_sp = []\n",
    "    \n",
    "    for i in range(num_chains):\n",
    "        # ith chain gets skips of p**i\n",
    "        skip = p**i\n",
    "        if random_start:\n",
    "            start_location = np.random.choice(N)\n",
    "        else:\n",
    "            start_location = 0\n",
    "        \n",
    "        sp = np.arange(start_location, \n",
    "                       start_location+skip*num_samples_per_chain, \n",
    "                       skip)\n",
    "        sp = sp % N\n",
    "        chains.append(sp)\n",
    "    return chains\n",
    "    \n",
    "    \n",
    "\n",
    "def make_kay_chains(w0, num_chains, num_samples_per_chain, snrdb, p=2):\n",
    "    \"\"\"\n",
    "    Function to make chains for successive estimation using Kay's method\n",
    "    \"\"\"\n",
    "    # this is a list of arrays\n",
    "    # it has num_chains many elements\n",
    "    # each element is an array of length num_samples_per_chain\n",
    "    chains = []\n",
    "    # noise variance\n",
    "    sigma2 = get_sigma2_from_snrdb(snrdb)\n",
    "    \n",
    "    for i in range(num_chains):\n",
    "        # first chain gets samples with skipping 1\n",
    "        # second chain gets samples with skipping 2, etc...\n",
    "        skip = p**i\n",
    "        # skip needs to be passed\n",
    "        noisy_signal = make_noisy_signal(w=w0,\n",
    "                                         theta=0,\n",
    "                                         sigma2=sigma2,\n",
    "                                         n=num_samples_per_chain,\n",
    "                                         skip=skip)\n",
    "        \n",
    "        # append to the chain\n",
    "        chains.append(noisy_signal)\n",
    "    return chains\n",
    "\n",
    "def make_our_chains(w0,\n",
    "                    n,\n",
    "                    num_pairs_per_chain,\n",
    "                    snrdb,\n",
    "                    prime_base=2,\n",
    "                    num_samples_per_pair=2,\n",
    "                    other_factor=1):\n",
    "    '''\n",
    "    n = what power of two is the signal\n",
    "    '''\n",
    "    # chains is a list of lists\n",
    "    # it has n elements\n",
    "    # each element is a list of tuples (sample1, sample2)\n",
    "    chains = []\n",
    "    # sampling_points is a list of lists\n",
    "    # it has n elements\n",
    "    # each element is a list of tuples (sampling_location_1, sampling_location_2)\n",
    "    sampling_points = []\n",
    "    sigma2 = get_sigma2_from_snrdb(snrdb)\n",
    "    \n",
    "    # you start by skipping signal_length/2\n",
    "    skip = other_factor*prime_base**(n-1)\n",
    "    \n",
    "    for i in range(n):\n",
    "        current_chain = []\n",
    "        current_sampling_points = []\n",
    "        \n",
    "        # poisition of the first sample\n",
    "        shift = 0\n",
    "        for i in range(num_pairs_per_chain):\n",
    "            signal = make_signal(w0,0,num_samples_per_pair,skip,shift)\n",
    "            noise  = make_noise(sigma2,num_samples_per_pair)\n",
    "            noisy_signal = signal + noise\n",
    "            current_chain.append(tuple(noisy_signal))\n",
    "            current_sampling_points.append(tuple([shift + i*skip for i in range(num_samples_per_pair)]))\n",
    "            shift += 1\n",
    "        chains.append(current_chain)\n",
    "        sampling_points.append(current_sampling_points)\n",
    "        # halve the skip\n",
    "        skip /= prime_base\n",
    "    return chains, sampling_points\n",
    "\n",
    "# make chain\n",
    "# make sub chains\n",
    "\n",
    "def make_our_locations(n,\n",
    "                       num_pairs_per_chain,\n",
    "                       prime_base=2,\n",
    "                       num_samples_per_pair=2,\n",
    "                       other_factor=1):\n",
    "    '''\n",
    "    n = what power of two is the signal\n",
    "    '''\n",
    "    # chains is a list of lists\n",
    "    # it has n elements\n",
    "    # each element is a list of tuples (sample1, sample2)\n",
    "    chains = []\n",
    "    # sampling_points is a list of lists\n",
    "    # it has n elements\n",
    "    # each element is a list of tuples (sampling_location_1, sampling_location_2)\n",
    "    sampling_points = []\n",
    "    \n",
    "    # you start by skipping signal_length/2\n",
    "    skip = other_factor*prime_base**(n-1)\n",
    "    \n",
    "    for i in range(n):\n",
    "        current_sampling_points = []\n",
    "        \n",
    "        # poisition of the first sample\n",
    "        shift = 0\n",
    "        for i in range(num_pairs_per_chain):\n",
    "            current_sampling_points.append(tuple([shift,shift+skip]))\n",
    "            shift += 1\n",
    "        sampling_points.append(current_sampling_points)\n",
    "        # halve the skip\n",
    "        skip /= prime_base\n",
    "    return sampling_points\n",
    "\n",
    "def estimate_bit_diff(chain,\n",
    "                      sampling_points,\n",
    "                      ref_w0):\n",
    "    '''\n",
    "    chain: pairs of samples obtained from the chain\n",
    "    sampling_points: the points at which the samples are obtained\n",
    "    ref_w0: the reference frequency obtained so far\n",
    "    '''\n",
    "    # complex valued estimate of the sign\n",
    "    d = 0\n",
    "    # number of pairs in a chain\n",
    "    len_chain = len(chain)\n",
    "    # go over the chain\n",
    "    for i in range(len_chain):\n",
    "        # where the samples are taken\n",
    "        s1,s2 = sampling_points[i]\n",
    "        # the sample values\n",
    "        a,b = chain[i]\n",
    "        # rotate the frequency based on the reference\n",
    "        a = a*np.exp(-1j*ref_w0*s1)\n",
    "        b = b*np.exp(-1j*ref_w0*s2)\n",
    "        # check the sign\n",
    "        d += (b - a)\n",
    "    # average the sign\n",
    "    # (this would change if there is a covariance between estimates)\n",
    "    # (we get around this by taking non-overlapping samples)\n",
    "    d /= len_chain\n",
    "    \n",
    "    # sign (returns -1 or 1)\n",
    "    estimated_sign = np.sign(np.real(d) + 1)\n",
    "    \n",
    "    \n",
    "#     print('jump: {} - {} = {}'.format(s2,s1,s2-s1))\n",
    "#     print(d + 1)\n",
    "#     print('sign: {}'.format(estimated_sign))\n",
    "    return estimated_sign\n",
    "\n",
    "def estimate_bit(chain,\n",
    "                 sampling_points,\n",
    "                 ref_w0,\n",
    "                 prime_base=2):\n",
    "    '''\n",
    "    chain: pairs of samples obtained from the chain\n",
    "    sampling_points: the points at which the samples are obtained\n",
    "    ref_w0: the reference frequency obtained so far\n",
    "    p: prime that is equal to the base\n",
    "    '''\n",
    "    # complex valued estimate of the sign\n",
    "    d = 0\n",
    "    # number of pairs in a chain\n",
    "    len_chain = len(chain)\n",
    "    # go over the chain\n",
    "    for i in range(len_chain):\n",
    "        # where the samples are taken\n",
    "        s1,s2 = sampling_points[i]\n",
    "        # the sample values\n",
    "        a,b = chain[i]\n",
    "        # rotate the frequency based on the reference\n",
    "        a = a*np.exp(-1j*ref_w0*s1)\n",
    "        b = b*np.exp(-1j*ref_w0*s2)\n",
    "        # check the sign\n",
    "        d += b*np.conj(a)\n",
    "    # average the sign\n",
    "    # (this would change if there is a covariance between estimates)\n",
    "    # (we get around this by taking non-overlapping samples)\n",
    "    d /= len_chain\n",
    "    \n",
    "    # rotate according to decision boundaries\n",
    "    # we need to rotate by 2pi/(2prime_base)\n",
    "    # this is to make one of the boundaries of the\n",
    "    # voronoi cells touch the positive side of x-axis\n",
    "    # so we can just return the integer part of a number\n",
    "    # to get the bit\n",
    "    d *= np.exp(1j*np.pi/prime_base)\n",
    "    # get the angle and normalize by 2pi\n",
    "    angle = np.angle(d)/2/np.pi\n",
    "    # angle is between (-0.5,0.5), take\n",
    "    # the mod to make it between (0,1)\n",
    "    angle = angle % 1\n",
    "    # return which voronoi cell the angle falls into\n",
    "    # it falls to gaps of 1/prime_base so multiply\n",
    "    # with prime base and get the integer part\n",
    "    return int(angle*prime_base)\n",
    "\n",
    "def estimate_bit_ml(chain,\n",
    "                    sampling_points,\n",
    "                    ref_w0,\n",
    "                    prime_base=2,\n",
    "                    statistics_function=np.real):\n",
    "    '''\n",
    "    chain:               pairs of samples obtained from the chain\n",
    "    sampling_points:     the points at which the samples are obtained\n",
    "    ref_w0:              the reference frequency obtained so far\n",
    "    p:                   prime that is equal to the base\n",
    "    statistics_function: when we know the amplitude we can use np.real \n",
    "                         as the statistics function.  However, when the\n",
    "                         coefficient is not known, we need to use np.abs\n",
    "    '''\n",
    "    # number of pairs in a chain\n",
    "    len_chain = len(chain)\n",
    "    max_inprod = -np.inf\n",
    "    best_loc = 0\n",
    "    \n",
    "    # these were sampling_points[0] and chain[0]\n",
    "    # sampling_points = np.array(sampling_points)\n",
    "    # chain = np.array(chain)\n",
    "    \n",
    "    rotater = np.exp(-1j*ref_w0*sampling_points)\n",
    "    chain = chain*rotater\n",
    "    \n",
    "    # go over possible bits\n",
    "    t = np.arange(len(sampling_points))\n",
    "    for l in range(prime_base):\n",
    "        steering_vector = np.exp(-1j*2*np.pi*l*t/prime_base)\n",
    "        current_inprod = chain.dot(steering_vector)\n",
    "        # can we look at the real part here when we have \n",
    "        # phase in the problem or equivalently there is a\n",
    "        # coefficient in front of the tone.  If we change \n",
    "        # this to abs we loose a lot of performance in terms\n",
    "        # of the number of samples\n",
    "        if statistics_function(current_inprod) > max_inprod:\n",
    "            max_inprod = statistics_function(current_inprod)\n",
    "            best_loc = l\n",
    "    return int(best_loc)\n",
    "\n",
    "def estimate_bit_sub_ml(chain,\n",
    "                        sampling_points,\n",
    "                        ref_w0,\n",
    "                        prime_base=2,\n",
    "                        statistics_function=np.median):\n",
    "    '''\n",
    "    chain: signal samples (list of arrays)\n",
    "    sampling_points: the points at which the samples are obtained (list of arrays)\n",
    "    ref_w0: the reference frequency obtained so far\n",
    "    p: prime that is equal to the base\n",
    "    '''\n",
    "    # here we assume there are multiple pairs per chain\n",
    "    # so we cannot do single chain computation like the\n",
    "    # ml version\n",
    "    # this is the number of sub-chains\n",
    "    len_chain = len(chain)\n",
    "    max_metric = -np.inf\n",
    "    best_loc = 0\n",
    "    t = np.arange(len(sampling_points[0]))\n",
    "    # go over possible bits\n",
    "    for l in range(prime_base):\n",
    "        sum_metric = 0\n",
    "        steering_vector = np.exp(-1j*2*np.pi*l*t/prime_base)\n",
    "        \n",
    "        the_inprods = []\n",
    "        # go over the sub-chains\n",
    "        for batch, sp in zip(chain,sampling_points):\n",
    "            # we need to use this rotater!\n",
    "            rotater = np.exp(-1j*ref_w0*sp)\n",
    "            batch = batch*rotater\n",
    "            current_inprod = batch.dot(steering_vector)\n",
    "            the_inprods.append(np.abs(current_inprod))\n",
    "        \n",
    "        sum_metric = statistics_function(the_inprods)\n",
    "        \n",
    "        if sum_metric > max_metric:\n",
    "            max_metric = sum_metric\n",
    "            best_loc = l\n",
    "    return int(best_loc)\n",
    "\n",
    "def get_correlation_with_steering_vector(yx, sp, w0, sv):\n",
    "    rotater = np.exp(-1j*w0*sp)\n",
    "    yx = yx*rotater\n",
    "    current_inprod = yx.dot(sv)\n",
    "    return current_inprod\n",
    "    \n",
    "\n",
    "def our_method(all_chains,\n",
    "               all_sampling_points,\n",
    "               prime_base=2,\n",
    "               bin_estimator=estimate_bit):\n",
    "    # start with reference 0\n",
    "    ref_w0 = 0\n",
    "    n = len(all_chains)\n",
    "    # signal length\n",
    "    N = prime_base**n\n",
    "    # go over chains\n",
    "    for i in range(n):\n",
    "        current_chain = all_chains[i]\n",
    "        current_smapling_points = all_sampling_points[i]\n",
    "        # estimate the bit\n",
    "        current_bit = bin_estimator(current_chain,\n",
    "                                    current_smapling_points,\n",
    "                                    ref_w0,\n",
    "                                    prime_base)\n",
    "        # if the current bit is -1 it means we are odd with\n",
    "        # respect to ith bit of the frequency\n",
    "        ref_w0 += current_bit*(prime_base**i)*(2*np.pi)/N\n",
    "    return ref_w0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, w, theta, sigma2):\n",
    "        self.w = w\n",
    "        self.theta = theta\n",
    "        self.sigma2 = sigma2\n",
    "        self.noise_scaling = np.sqrt(sigma2/2)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        signal = np.exp(1j*(self.w*n+ self.theta))\n",
    "        noise  = noise_scaling*np.random.randn(n) + 1j*noise_scaling*np.random.randn(n)\n",
    "        return signal+noise\n",
    "        \n",
    "class OnePeriodSampler:\n",
    "    def __init__(self, w, theta, sigma2):\n",
    "        self.w = w\n",
    "        self.theta = theta\n",
    "        self.sigma2 = sigma2\n",
    "        self.noise_scaling = np.sqrt(sigma2/2)\n",
    "        self.already_generated = {}\n",
    "    \n",
    "    def sample(self, n):\n",
    "        if n in self.already_generated:\n",
    "            return self.already_generated[n]\n",
    "        else:\n",
    "            signal = np.exp(1j*(self.w*n+ self.theta))\n",
    "            noise  = noise_scaling*np.random.randn(n) + 1j*noise_scaling*np.random.randn(n)\n",
    "            return signal+noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 1\n",
    "\n",
    "Here I test our algorithm under independent noise and infinite-length signal setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_many(f, num_iter, **kwargs):\n",
    "    r = []\n",
    "    for i in range(num_iter):\n",
    "        r.append(f(**kwargs))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ml(p, n, samples_per_chain, f0, snrdb, statistics_function=np.real, premake=False):\n",
    "    \"\"\"\n",
    "    Make the one with the signal pre-made.\n",
    "    \"\"\"\n",
    "    N = p**n\n",
    "    w0 = (2*np.pi)*f0/N\n",
    "    s2 = get_sigma2_from_snrdb(snrdb)\n",
    "    \n",
    "    # this is the setting where we are given a single period from the signal\n",
    "    if premake:\n",
    "        x = make_noisy_signal(w0, theta=0, sigma2=s2, n=N, skip=1)\n",
    "    \n",
    "    c_so_far = 0\n",
    "    for chain in range(n):\n",
    "        skip = p**(n-1-chain)\n",
    "        ref_w0 = (2*np.pi)*c_so_far/N\n",
    "        if not premake:\n",
    "            y = make_noisy_signal(w0, theta=0, sigma2=s2, n=samples_per_chain, skip=skip)\n",
    "            sampling_points = np.arange(0, samples_per_chain*skip, skip)\n",
    "        else:\n",
    "            random_shift = np.random.choice(N)\n",
    "            sampling_points = np.arange(random_shift, samples_per_chain*skip+random_shift, skip)\n",
    "            sampling_points = sampling_points % N\n",
    "            y = x[sampling_points]\n",
    "            \n",
    "        bit = estimate_bit_ml(y, sampling_points, ref_w0, prime_base=p, statistics_function=statistics_function)\n",
    "        c_so_far += bit * (p**chain)\n",
    "    \n",
    "    return int(c_so_far == f0)\n",
    "\n",
    "def test_sub_ml(p, n, samples_per_chain, num_chains, f0, snrdb, statistics_function=np.median, alternate=False):\n",
    "    N = p**n\n",
    "    w0 = (2*np.pi)*f0/N\n",
    "    s2 = get_sigma2_from_snrdb(snrdb)\n",
    "    \n",
    "    c_so_far = 0\n",
    "    for chain in range(n):\n",
    "        skip = p**(n-1-chain)\n",
    "        ref_w0 = (2*np.pi)*c_so_far/N\n",
    "        \n",
    "        current_samples = []\n",
    "        current_sampling_points = []\n",
    "        \n",
    "        # make this using map function instead to speed up the computations\n",
    "        for sub_chain in range(num_chains):\n",
    "            y = make_noisy_signal(w0, theta=0, sigma2=s2, n=samples_per_chain, skip=skip)\n",
    "            t = np.arange(0, samples_per_chain*skip, skip)\n",
    "            current_samples.append(y)\n",
    "            current_sampling_points.append(t)\n",
    "        \n",
    "        bit = estimate_bit_sub_ml(current_samples,\n",
    "                                  current_sampling_points, \n",
    "                                  ref_w0,\n",
    "                                  prime_base=p,\n",
    "                                  statistics_function=statistics_function)\n",
    "        \n",
    "        c_so_far += bit * (p**chain)\n",
    "        \n",
    "        if alternate:\n",
    "            if num_chains > 2:\n",
    "                num_chains = max(num_chains // 2, 1)\n",
    "                samples_per_chain = samples_per_chain * 2\n",
    "    \n",
    "    return int(c_so_far == f0)\n",
    "\n",
    "def test_mixed_ml(p, n, m, f0, snrdb, summing_power=1):\n",
    "    \"\"\"\n",
    "    p:  prime factor\n",
    "    n:  power of the prime\n",
    "    m:  initial number of bits to recover\n",
    "    f0: \n",
    "    snrdb:\n",
    "    summing_power:\n",
    "    \"\"\"\n",
    "    N = p**n\n",
    "    w0 = (2*np.pi)*f0/N\n",
    "    s2 = get_sigma2_from_snrdb(snrdb)\n",
    "    \n",
    "    c_so_far = 0\n",
    "    skip = None\n",
    "    num_recovered_bits = 0\n",
    "    \n",
    "    samples_per_chain = p**m\n",
    "    \n",
    "    while num_recovered_bits < n:\n",
    "        if num_recovered_bits == 0:\n",
    "            skip = p**(n-m)\n",
    "            current_recovered_bits = m\n",
    "        else:\n",
    "            skip = p**(n-num_recovered_bits-1)\n",
    "            current_recovered_bits = 1\n",
    "            \n",
    "        ref_w0 = (2*np.pi)*c_so_far/N\n",
    "        \n",
    "        current_samples = []\n",
    "        current_sampling_points = []\n",
    "        \n",
    "\n",
    "        y = make_noisy_signal(w0, theta=0, sigma2=s2, n=samples_per_chain, skip=skip)\n",
    "        t = np.arange(0, samples_per_chain*skip, skip)\n",
    "        current_samples.append(y)\n",
    "        current_sampling_points.append(t)\n",
    "        \n",
    "        bit = estimate_bit_sub_ml(current_samples,\n",
    "                                  current_sampling_points, \n",
    "                                  ref_w0,\n",
    "                                  prime_base=p**current_recovered_bits,\n",
    "                                  summing_power=summing_power)\n",
    "        \n",
    "        c_so_far += bit * (p**num_recovered_bits)\n",
    "        \n",
    "    \n",
    "        num_recovered_bits += current_recovered_bits\n",
    "    return int(c_so_far == f0)\n",
    "\n",
    "def test_kays(p, n, num_samples, f0, snrdb):\n",
    "    N = p**n\n",
    "    w0 = (2*np.pi)*f0/N\n",
    "    s2 = get_sigma2_from_snrdb(snrdb)\n",
    "    \n",
    "    y = make_noisy_signal(w0, theta=0, sigma2=s2, n=num_samples, skip=1)\n",
    "    freq = kays_method(y)\n",
    "    \n",
    "    return freq\n",
    "\n",
    "def test_successive_estimation(p, n, samples_per_chain, num_chains, f0, snrdb, summing_power=1):\n",
    "    N = p**n\n",
    "    w0 = (2*np.pi)*f0/N\n",
    "    s2 = get_sigma2_from_snrdb(snrdb)\n",
    "    \n",
    "    chains = make_kay_chains(w0, num_chains, samples_per_chain, snrdb, p=2)\n",
    "    f0_hat = successive_estimation(chains, N, p=2, rounding=None)\n",
    "    \n",
    "    return int(f0_hat == f0)\n",
    "\n",
    "\n",
    "def test_linear_ml(p, n, samples_per_chain, f0, snrdb):\n",
    "    \"\"\"\n",
    "    Make the one with the signal pre-made.\n",
    "    \"\"\"\n",
    "    N = p**n\n",
    "    w0 = (2*np.pi)*f0/N\n",
    "    s2 = get_sigma2_from_snrdb(snrdb)\n",
    "    \n",
    "    sampling_points = np.random.choice(N, samples_per_chain, replace=False)\n",
    "    \n",
    "#     sampling_points = np.arange(samples_per_chain)\n",
    "    \n",
    "    signal = np.exp(1j*(w0*sampling_points))\n",
    "    noise  = make_noise(s2, samples_per_chain)\n",
    "    noisy_signal = signal + noise\n",
    "    \n",
    "    y = np.zeros(N, dtype=np.complex)\n",
    "    y[sampling_points] = noisy_signal\n",
    "    \n",
    "    v = np.fft.fft(y)\n",
    "    v = np.abs(v)\n",
    "    \n",
    "    k_hat = np.argmax(v)\n",
    "    \n",
    "    return int(k_hat == f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kays(p=2, n=20, num_samples=200, f0=0, snrdb=0)*(2**20)/2/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kays_method = kays_method3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 2**9-1\n",
    "n = 20\n",
    "snrdb = -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# successive estimation\n",
    "# I observe that frequency location 0 is very well found with\n",
    "# samples per chain=200\n",
    "# snrdb=0\n",
    "# f0=0\n",
    "# for any other f0 it is around 1/4.\n",
    "\n",
    "q = run_many(test_successive_estimation, 1000, p=2, n=n, samples_per_chain=256, \n",
    "             num_chains=n, f0=f0, snrdb=snrdb)\n",
    "np.mean(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ML multi-period\n",
    "q = run_many(test_ml, 1000, p=2, n=n, samples_per_chain=256, f0=f0,\n",
    "             statistics_function=np.abs, snrdb=snrdb, premake=False)\n",
    "np.mean(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML single period\n",
    "q = run_many(test_ml, 1000, p=2, n=n, samples_per_chain=2, f0=f0,\n",
    "             statistics_function=np.abs, snrdb=snrdb, premake=True)\n",
    "np.mean(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-ML multi-period\n",
    "# my_function = lambda x: np.mean(np.array(x)**2)\n",
    "my_function = lambda x: np.mean(x)\n",
    "# my_function = lambda x: np.mean(np.sqrt(x))\n",
    "# my_function = lambda x: np.median(x)\n",
    "q = run_many(test_sub_ml, 1000, p=2, n=n, samples_per_chain=2, num_chains=256,\n",
    "             f0=f0, snrdb=snrdb, statistics_function=my_function, alternate=True)\n",
    "np.mean(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_confint(len(q), len(q), alpha=0.05, method='beta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collecting data for plot generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['method','p','n','f0','snrdb','samples_per_chain','num_chains','iter','success'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bit ML\n",
    "num_iter = 10000\n",
    "p = 2\n",
    "n = 20\n",
    "f0 = 23\n",
    "snrdb = 0\n",
    "for samples_per_chain in tqdm(np.arange(1,10)*2):\n",
    "    q = run_many(test_ml, num_iter, p=p, n=n, samples_per_chain=samples_per_chain, f0=f0, snrdb=snrdb)\n",
    "    \n",
    "    entry = {'method':'ml', 'p':p, 'n':n, 'f0':f0, 'snrdb':snrdb, 'samples_per_chain':samples_per_chain, 'num_chains':1, 'iter':num_iter, 'success':sum(q)}\n",
    "    df = df.append(entry, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bit MLUK\n",
    "num_iter = 10000\n",
    "p = 2\n",
    "n = 20\n",
    "f0 = 23\n",
    "snrdb = 0\n",
    "for samples_per_chain in tqdm(np.arange(1,10)*2):\n",
    "    q = run_many(test_ml, num_iter, p=p, n=n, samples_per_chain=samples_per_chain, f0=f0, snrdb=snrdb, statistics_function=np.abs)\n",
    "    \n",
    "    entry = {'method':'mluk', 'p':p, 'n':n, 'f0':f0, 'snrdb':snrdb, 'samples_per_chain':samples_per_chain, 'num_chains':1, 'iter':num_iter, 'success':sum(q)}\n",
    "    df = df.append(entry, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bit sub ML\n",
    "num_iter = 10000\n",
    "p = 2\n",
    "n = 20\n",
    "f0 = 23\n",
    "snrdb = 0\n",
    "samples_per_chain = p\n",
    "for num_chains in tqdm(range(1,20,1)):\n",
    "    q = run_many(test_sub_ml, num_iter, \n",
    "                 p=p, \n",
    "                 n=n, \n",
    "                 samples_per_chain=samples_per_chain, \n",
    "                 num_chains=num_chains, \n",
    "                 f0=f0, \n",
    "                 snrdb=snrdb,\n",
    "                 summing_power=1)\n",
    "    \n",
    "    entry = {'method':'subml', 'p':p, 'n':n, 'f0':f0, 'snrdb':snrdb, 'samples_per_chain':samples_per_chain, 'num_chains':num_chains, 'iter':num_iter, 'success':sum(q)}\n",
    "    df = df.append(entry, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_samples'] = df['samples_per_chain']*df['num_chains']\n",
    "df['success_prob'] = df['success']/df['iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is an error in the sub-ml code, in the beginning increasing the number of samples seem to hurt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subml_data = df[df['method'] == 'subml']\n",
    "ml_data = df[df['method'] == 'ml']\n",
    "mluk_data = df[df['method'] == 'mluk']\n",
    "plt.semilogx(1-subml_data['success_prob'], subml_data['total_samples'], label='sub-ml')\n",
    "plt.semilogx(1-ml_data['success_prob'], ml_data['total_samples'], label='ml')\n",
    "plt.semilogx(1-mluk_data['success_prob'], mluk_data['total_samples'], label='mluk')\n",
    "plt.legend()\n",
    "plt.xlabel('error probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(outfile, column_names, *args):\n",
    "    with open(outfile, 'w') as out:\n",
    "        out.write(' '.join(column_names) + '\\n')\n",
    "        for z in zip(*args):\n",
    "            z = [str(zi) for zi in z]\n",
    "            out.write(' '.join(z))\n",
    "            out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data('plotting/experiment-1/out-ml.txt', \n",
    "           ['d','m'], \n",
    "           np.array(1-ml_data['success_prob']), \n",
    "           np.array(ml_data['total_samples']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data('plotting/experiment-1/out-mluk.txt', \n",
    "           ['d','m'], \n",
    "           np.array(1-mluk_data['success_prob']), \n",
    "           np.array(mluk_data['total_samples']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data('plotting/experiment-1/out-subml.txt',\n",
    "           ['d','m'], \n",
    "           np.array(1-subml_data['success_prob']), \n",
    "           np.array(subml_data['total_samples']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing icassp 2019 method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for testing our method\n",
    "n = 20\n",
    "p = 2\n",
    "f0 = 10\n",
    "snrdb = 2\n",
    "\n",
    "N = p**n\n",
    "w0 = (2*np.pi)*f0/N\n",
    "s2 = get_sigma2_from_snrdb(snrdb)\n",
    "\n",
    "num_correct = 0\n",
    "num_iter = 1000\n",
    "\n",
    "# samples_per_chain = int(np.ceil(2*s2*np.log(n*p/0.05)))\n",
    "samples_per_chain = 6\n",
    "print('samples per chain: {}'.format(samples_per_chain))\n",
    "print('total samples: {}'.format(n*samples_per_chain))\n",
    "\n",
    "for i in range(num_iter):\n",
    "    c_so_far = 0\n",
    "    for chain in range(n):\n",
    "        skip = p**(n-1-chain)\n",
    "        ref_w0 = (2*np.pi)*c_so_far/N\n",
    "        y = make_noisy_signal(w0, theta=0, sigma2=s2, n=samples_per_chain, skip=skip)\n",
    "        sampling_points = np.arange(0, samples_per_chain*skip, skip)\n",
    "        bit = estimate_bit_ml(y, sampling_points, ref_w0, prime_base=p)\n",
    "        c_so_far += bit * (p**chain)\n",
    "    num_correct += (c_so_far == f0)\n",
    "    \n",
    "print('success: {}'.format(num_correct/num_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot in kay's paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kay_weights(20),'-*')\n",
    "plt.plot(kay_weights(10),'-*')\n",
    "plt.plot(kay_weights(5),'-*')\n",
    "plt.axhline(0.07, c='r')\n",
    "plt.axhline(0.08, c='r')\n",
    "# plt.ylim([0.01,0.10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kay as a function of number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "n = 20\n",
    "f0 = 0\n",
    "\n",
    "r = run_many(test_kays, 5000, p=p, n=n, num_samples=15, f0=f0, snrdb=20)\n",
    "print('var: {}'.format( np.mean((np.array(r) - 2*np.pi*f0/(p**n))**2) ))\n",
    "plt.plot(r)\n",
    "plt.axhline(2*np.pi*f0/(p**n), color='C1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r,bins=40)\n",
    "plt.axvline(0,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "stats.probplot(r, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kays_method = kays_method3\n",
    "run_many(test_kays, 1, p=4, n=1, num_samples=4, f0=3, snrdb=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_many(test_kays, 1, p=8, n=1, num_samples=4, f0=7, snrdb=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error(r, ref):\n",
    "    angle_diff = np.angle(np.exp(1j*r)*np.conj(ref))\n",
    "    return np.mean((angle_diff/2/np.pi)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrdb_points = np.linspace(-10,40,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 1\n",
    "p = 20\n",
    "n = 1\n",
    "N = p**n\n",
    "\n",
    "results = []\n",
    "kays_method = kays_method1\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    r = run_many(test_kays, 1000, p=p, n=n, num_samples=100, f0=f0, snrdb=snrdb)\n",
    "    results.append(np.array(r))\n",
    "    \n",
    "rs = [0 for i in range(len(results))]\n",
    "for i in range(len(results)):\n",
    "    rs[i] = calc_error(results[i], np.exp(1j*2*np.pi*f0/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting for kay's plots is:\n",
    "`r = run_many(test_kays, 100, p=20, n=1, num_samples=24, f0=f0, snrdb=snrdb)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 1\n",
    "p = 20\n",
    "n = 1\n",
    "N = p**n\n",
    "\n",
    "results_2 = []\n",
    "kays_method = kays_method3\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    r = run_many(test_kays, 1000, p=p, n=n, num_samples=100, f0=f0, snrdb=snrdb)\n",
    "    results_2.append(np.array(r))\n",
    "    \n",
    "rs_2 = [0 for i in range(len(results_2))]\n",
    "for i in range(len(rs_2)):\n",
    "    rs_2[i] = calc_error(results_2[i], np.exp(1j*2*np.pi*f0/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_db(u):\n",
    "    return 10*np.log10(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.array(rs)\n",
    "rs_2 = np.array(rs_2)\n",
    "\n",
    "plt.plot(snrdb_points, to_db(1/rs), label='plot1')\n",
    "plt.plot(snrdb_points, to_db(1/rs_2), label='plot2')\n",
    "plt.axvline(8, c='r')\n",
    "plt.axvline(10, c='r')\n",
    "plt.xlabel('snrdb')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0,100])\n",
    "plt.xlim([-10,40])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I observe 10db per decade decrease until 6 db, then 20db per decade.  How about our algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kay's probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrdb_points = np.linspace(-20,10,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(omegas, p, f0):\n",
    "    omegas = omegas/(2*np.pi)\n",
    "    omegas = (omegas+1/(p*2)) % 1\n",
    "    f0_hat = np.floor(omegas*p)\n",
    "    return np.mean(f0_hat == f0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 0\n",
    "p = 2\n",
    "n = 1\n",
    "N = p**n\n",
    "\n",
    "results = []\n",
    "kays_method = kays_method3\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    r = run_many(test_kays, 1000, p=p, n=n, num_samples=4, f0=f0, snrdb=snrdb)\n",
    "    results.append(np.array(r))\n",
    "    \n",
    "rs = [0 for i in range(len(results))]\n",
    "for i in range(len(results)):\n",
    "    rs[i] = calc_acc(results[i], p, f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 0\n",
    "p = 2\n",
    "n = 1\n",
    "N = p**n\n",
    "\n",
    "rs_2 = []\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    # Sub-ML multi-period\n",
    "    q = run_many(test_sub_ml, 1000, p=p, n=n, samples_per_chain=2, num_chains=2,\n",
    "                 f0=f0, snrdb=snrdb, summing_power=2, alternate=True)\n",
    "    rs_2.append(np.mean(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.array(rs)\n",
    "rs_2 = np.array(rs_2)\n",
    "\n",
    "plt.plot(snrdb_points, rs, label='kay')\n",
    "plt.plot(snrdb_points, rs_2, label='sub-ml')\n",
    "plt.axvline(6, c='r')\n",
    "plt.xlabel('snrdb')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0,1.2])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## successive refinement probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrdb_points = np.linspace(-20,20,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 20*16\n",
    "print('total samples: {}'.format(total_samples))\n",
    "\n",
    "signal_length = 2**20\n",
    "print('sampling rate: {}%'.format(100*total_samples/signal_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "n = 20\n",
    "f0 = 0\n",
    "N = p**n\n",
    "\n",
    "rs = []\n",
    "kays_method = kays_method3\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    q = run_many(test_successive_estimation, 100, p=p, n=n, samples_per_chain=16, \n",
    "             num_chains=n, f0=f0, snrdb=snrdb)\n",
    "    rs.append(np.mean(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "n = 20\n",
    "f0 = 2**(n-2)\n",
    "N = p**n\n",
    "\n",
    "rs_2 = []\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    # Sub-ML multi-period\n",
    "    q = run_many(test_sub_ml, 1000, p=p, n=n, samples_per_chain=2, num_chains=16,\n",
    "                 f0=f0, snrdb=snrdb, summing_power=2, alternate=True)\n",
    "    rs_2.append(np.mean(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the multiple bits at a time case\n",
    "p = 16\n",
    "n = 5\n",
    "f0 = 2**18\n",
    "N = p**n\n",
    "\n",
    "rs_3 = []\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    # Sub-ML multi-period\n",
    "    q = run_many(test_sub_ml, 1000, p=p, n=n, samples_per_chain=16, num_chains=1,\n",
    "                 f0=f0, snrdb=snrdb, summing_power=2, alternate=True)\n",
    "    rs_3.append(np.mean(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the one above has much less number of samples actually $16 \\times 5$ vs. $16 \\times 20$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "n = 20\n",
    "f0 = 0\n",
    "N = p**n\n",
    "\n",
    "rs_ml = []\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    # Sub-ML multi-period\n",
    "    q = run_many(test_sub_ml, 100, p=p, n=n, samples_per_chain=16, num_chains=1,\n",
    "                 f0=f0, snrdb=snrdb, summing_power=2, alternate=False)\n",
    "    rs_ml.append(np.mean(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "n = 1\n",
    "f0 = 0\n",
    "N = p**n\n",
    "\n",
    "rs_true_ml = []\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    # Sub-ML multi-period\n",
    "    q = run_many(test_ml, 10000, p=p, n=n, samples_per_chain=200, f0=f0, snrdb=snrdb)\n",
    "    rs_true_ml.append(np.mean(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "n = 20\n",
    "f0 = 2**(n-2)\n",
    "N = p**n\n",
    "\n",
    "rs_mixed = []\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    # Sub-ML multi-period\n",
    "    q = run_many(test_mixed_ml, 1000, p=p, n=n, m=4,\n",
    "                 f0=f0, snrdb=snrdb, summing_power=2)\n",
    "    rs_mixed.append(np.mean(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "n = 20\n",
    "f0 = 0\n",
    "N = p**n\n",
    "\n",
    "\n",
    "test_linear_ml(p=p, n=n, samples_per_chain=64, f0=f0, snrdb=-10)\n",
    "\n",
    "rs_linear_ml = []\n",
    "for snrdb in tqdm(snrdb_points):\n",
    "    # Sub-ML multi-period\n",
    "    q = run_many(test_linear_ml, 100, p=p, n=n, samples_per_chain=16*n, f0=f0, snrdb=snrdb)\n",
    "    rs_linear_ml.append(np.mean(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rs = np.array(rs)\n",
    "rs_2 = np.array(rs_2)\n",
    "rs_3 = np.array(rs_3)\n",
    "rs_ml = np.array(rs_ml)\n",
    "rs_mixed = np.array(rs_mixed)\n",
    "rs_true_ml = np.array(rs_true_ml)\n",
    "rs_linear_ml = np.array(rs_linear_ml)\n",
    "\n",
    "plt.plot(snrdb_points, rs, label='kay')\n",
    "# plt.plot(snrdb_points, rs_2, label='sub-ml')\n",
    "# plt.plot(snrdb_points, rs_3, label='sub-ml-multidigit')\n",
    "plt.plot(snrdb_points, rs_ml, label='ml')\n",
    "# plt.plot(snrdb_points, rs_true_ml, label='true-ml')\n",
    "# plt.plot(snrdb_points, rs_mixed, label='mixed-ml')\n",
    "plt.plot(snrdb_points, rs_linear_ml, label='linear-time-ml')\n",
    "# plt.axvline(6, c='r')\n",
    "plt.xlabel('snrdb')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0,1.2])\n",
    "plt.grid(True)\n",
    "plt.savefig('comparison.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(64*20)/(2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.array(rs)\n",
    "rs_2 = np.array(rs_2)\n",
    "rs_3 = np.array(rs_3)\n",
    "rs_ml = np.array(rs_ml)\n",
    "rs_mixed = np.array(rs_mixed)\n",
    "rs_true_ml = np.array(rs_true_ml)\n",
    "\n",
    "plt.plot(snrdb_points, to_db(np.log(1/(1-rs))), label='kay')\n",
    "# plt.plot(snrdb_points, rs_2, label='sub-ml')\n",
    "# plt.plot(snrdb_points, rs_3, label='sub-ml-multidigit')\n",
    "plt.plot(snrdb_points, to_db(np.log(1/(1-rs_ml))), label='ml')\n",
    "plt.plot(snrdb_points, to_db(np.log(1/(1-rs_true_ml))), label='true-ml')\n",
    "# plt.plot(snrdb_points, rs_mixed, label='mixed-ml')\n",
    "# plt.axvline(6, c='r')\n",
    "plt.xlabel('snrdb')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "# plt.ylim([0,1.2])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kays as a function of the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "n = 20\n",
    "f0 = 1\n",
    "\n",
    "num_samples_vec = np.arange(5,100,15)\n",
    "results_vec = []\n",
    "for num_samples in tqdm(num_samples_vec):\n",
    "    r = run_many(test_kays, 5000, p=p, n=n, num_samples=num_samples, f0=f0, snrdb=0)\n",
    "    var_output = np.mean((np.array(r) - 2*np.pi*f0/(p**n))**2)\n",
    "    results_vec.append(var_output)\n",
    "    # print('var: {}'.format( var_output ))\n",
    "\n",
    "results_vec = np.array(results_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_samples_vec, to_db(1/results_vec))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fixed snr plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_points = 2**np.arange(1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "n = 20\n",
    "f0 = 0\n",
    "N = p**n\n",
    "snrdb = -10\n",
    "\n",
    "rs_ml = []\n",
    "for m in tqdm(m_points):\n",
    "    # Sub-ML multi-period\n",
    "    q = run_many(test_sub_ml, 100, p=p, n=n, samples_per_chain=m, num_chains=1,\n",
    "                 f0=f0, snrdb=snrdb, summing_power=2, alternate=False)\n",
    "    rs_ml.append(np.mean(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "n = 20\n",
    "f0 = 0\n",
    "N = p**n\n",
    "snrdb = -10\n",
    "\n",
    "rs_linear_ml = []\n",
    "for m in tqdm(m_points):\n",
    "    # Sub-ML multi-period\n",
    "    q = run_many(test_linear_ml, 100, p=p, n=n, samples_per_chain=m*n, f0=f0, snrdb=snrdb)\n",
    "    rs_linear_ml.append(np.mean(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_ml = np.array(rs_ml)\n",
    "rs_linear_ml = np.array(rs_linear_ml)\n",
    "\n",
    "plt.plot(m_points*n, rs_ml, label='ml')\n",
    "plt.plot(m_points*n, rs_linear_ml, label='linear-time-ml')\n",
    "# plt.axvline(6, c='r')\n",
    "plt.xlabel('m')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0,1.2])\n",
    "plt.grid(True)\n",
    "plt.savefig('comparison.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = 10**(-snrdb/10)\n",
    "9*n*np.log(n)*s2/(p**n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix snr + change n > find m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_points = np.arange(2,64,2)\n",
    "print(m_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 2\n",
    "# f0 = 0\n",
    "# snrdb = 0\n",
    "\n",
    "\n",
    "# df_linear_ml = pd.DataFrame(columns=['n', 'samples', 'acc'])\n",
    "# for n in tqdm(np.arange(20,50,5), leave=False):\n",
    "#     N = p**n\n",
    "#     for m in tqdm(m_points):\n",
    "#         # Sub-ML multi-period\n",
    "#         num_samples = m*n\n",
    "#         q = run_many(test_linear_ml, 10, p=p, n=n, samples_per_chain=num_samples, f0=f0, snrdb=snrdb)\n",
    "        \n",
    "#         acc_hat = np.mean(q)\n",
    "        \n",
    "#         entry = {'n':n, 'samples':num_samples, 'acc':acc_hat}\n",
    "#         df_linear_ml = df_linear_ml.append(entry, ignore_index=True)\n",
    "# #         if acc_hat == 1:\n",
    "# #             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "f0 = 0\n",
    "snrdb = -5\n",
    "\n",
    "try:\n",
    "    df_ml\n",
    "except NameError: \n",
    "    df_ml = pd.DataFrame(columns=['n', 'samples', 'acc', 'snrdb'])\n",
    "\n",
    "m_min = 32\n",
    "m_max = 128\n",
    "for n in tqdm(np.arange(10,60,5)):\n",
    "    N = p**n\n",
    "    m_points = np.arange(m_min, m_max, 2)\n",
    "    for m in tqdm(m_points, leave=False, desc='n: {}'.format(n)):\n",
    "        # Sub-ML multi-period\n",
    "        num_samples = m*n\n",
    "        q = run_many(test_sub_ml, 5000, p=p, n=n, samples_per_chain=m, num_chains=1,\n",
    "                 f0=f0, snrdb=snrdb, summing_power=2, alternate=False)\n",
    "        acc_hat = np.mean(q)\n",
    "        entry = {'n':n, 'samples':num_samples, 'acc':np.mean(q), 'snrdb':snrdb}\n",
    "        df_ml = df_ml.append(entry, ignore_index=True)\n",
    "        if acc_hat < 0.8:\n",
    "            m_min = m\n",
    "        if acc_hat == 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "f0 = 0\n",
    "snrdb = -5\n",
    "\n",
    "try:\n",
    "    df_kay\n",
    "except NameError: \n",
    "    df_kay = pd.DataFrame(columns=['n', 'samples', 'acc', 'snrdb'])\n",
    "\n",
    "m_min = 160\n",
    "m_max = 300\n",
    "for n in tqdm(np.arange(10,60,5)):\n",
    "    N = p**n\n",
    "    m_points = np.arange(m_min, m_max, 2)\n",
    "    for m in tqdm(m_points, leave=False, desc='n: {}'.format(n)):\n",
    "        # Sub-ML multi-period\n",
    "        num_samples = m*n\n",
    "        q = run_many(test_successive_estimation, 5000, p=p, n=n,\n",
    "                     samples_per_chain=m, num_chains=n, f0=f0, snrdb=snrdb)\n",
    "        \n",
    "        acc_hat = np.mean(q)\n",
    "        entry = {'n':n, 'samples':num_samples, 'acc':np.mean(q), 'snrdb':snrdb}\n",
    "        df_kay = df_kay.append(entry, ignore_index=True)\n",
    "        if acc_hat < 0.8:\n",
    "            m_min = m\n",
    "        if acc_hat == 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = run_many(test_successive_estimation, 5000, p=p, n=n,\n",
    "                     samples_per_chain=200, num_chains=n, f0=f0, snrdb=snrdb)\n",
    "\n",
    "print(np.mean(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_for_acc(df, acc, snrdb):\n",
    "    n_vec = []\n",
    "    s_ml_vec = []\n",
    "    df_subset = df[df['snrdb']==snrdb]\n",
    "    for g, v in df_subset.groupby('n'):\n",
    "        samples_enough = v.iloc[np.where(v['acc'] > acc)[0][0]]['samples']\n",
    "        n_vec.append(g)\n",
    "        s_ml_vec.append(samples_enough)\n",
    "    n_vec = np.array(n_vec)\n",
    "    s_ml_vec = np.array(s_ml_vec)\n",
    "    return (2**n_vec, s_ml_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kay = df_kay[~((df_kay['snrdb']==-5) & (df_kay['n'] ==30))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import LogFormatterExponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.to_pickle('df_ml_m_vs_n.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kay.to_pickle('df_kay_m_vs_n.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(6,3.5))\n",
    "\n",
    "ax1.plot(*get_samples_for_acc(df_ml, 0.99, 0), '*-', label='this paper (0dB)')\n",
    "ax1.plot(*get_samples_for_acc(df_kay, 0.99, 0), 'x-', label='s.e. (0dB)')\n",
    "\n",
    "ax1.plot(*get_samples_for_acc(df_ml, 0.99, -5), '*-', label='this paper (-5dB)')\n",
    "ax1.plot(*get_samples_for_acc(df_kay, 0.99, -5), 'x-', label='s.e. (-5dB)')\n",
    "\n",
    "ax1.set_xscale('log', basex=2)\n",
    "ax1.set_xticks(2**np.arange(10,60,5))\n",
    "# ax1.get_xaxis().set_major_formatter(LogFormatterExponent(base=2))\n",
    "\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('number of samples')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('manuscript/figures/m-vs-n.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 2**np.arange(10,60,5):\n",
    "    print('{},'.format(i), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_samples_for_acc(df_ml, 0.99, 0)\n",
    "# ax1.plot(*get_samples_for_acc(df_kay, 0.99, 0), 'x-', label='s.e. (0dB)')\n",
    "\n",
    "# ax1.plot(*get_samples_for_acc(df_ml, 0.99, -5), '*-', label='this paper (-5dB)')\n",
    "# ax1.plot(*get_samples_for_acc(df_kay, 0.99, -5), 'x-', label='s.e. (-5dB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data('m-vs-n-ml-0.txt', ['n', 'm'], *get_samples_for_acc(df_ml, 0.99, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data('m-vs-n-ml-5.txt', ['n', 'm'], *get_samples_for_acc(df_ml, 0.99, -5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data('m-vs-n-kay-0.txt', ['n', 'm'], *get_samples_for_acc(df_kay, 0.99, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data('m-vs-n-kay-5.txt', ['n', 'm'], *get_samples_for_acc(df_kay, 0.99, -5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing successive estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing the successive estimation or kay's method\n",
    "n = 20\n",
    "p = 2\n",
    "f0 = 0\n",
    "snrdb = 10\n",
    "\n",
    "N = p**n\n",
    "w0 = (2*np.pi)*f0/N\n",
    "\n",
    "# odd number of delays are not working\n",
    "# fix this\n",
    "num_delays_per_chain = 2\n",
    "\n",
    "num_correct = 0\n",
    "num_iter = 1000\n",
    "\n",
    "# num_chains = int(np.log2(N))\n",
    "num_chains = n\n",
    "\n",
    "total_samples = num_chains*num_delays_per_chain\n",
    "print('total samples: {}'.format(total_samples))\n",
    "\n",
    "a_list = []\n",
    "\n",
    "for i in tqdm(range(num_iter)):\n",
    "    # successive estimation ----\n",
    "    A = make_kay_chains(w0,\n",
    "                        num_chains,\n",
    "                        num_delays_per_chain,\n",
    "                        snrdb)\n",
    "    # the one used in ffast paper\n",
    "    a = successive_estimation(A, N)\n",
    "    a_list.append(a)\n",
    "    # --------------------------\n",
    "    \n",
    "    # original kay's method ----\n",
    "#     a = omega_to_location(kays_method(make_kay_chains(w0, 1, total_samples, snrdb)[0]),N)\n",
    "    # --------------------------\n",
    "    \n",
    "    b = round(a) % N\n",
    "    num_correct += (b == f0)\n",
    "    \n",
    "print('success: {}'.format(num_correct/num_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_to_location(kays_method(A[0]),N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_number = 4060\n",
    "vnoise = make_noise(get_sigma2_from_snrdb(0),noise_number)\n",
    "np.sum(np.abs(vnoise)**2)/noise_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# kay with only possible locations active\n",
    "F1 = 32\n",
    "F2 = 25*27\n",
    "N = F1*F2\n",
    "\n",
    "print(\"N: {}\".format(N))\n",
    "\n",
    "f0 = np.random.choice(N)\n",
    "# f0 = 32\n",
    "\n",
    "print('f0: {}'.format(f0))\n",
    "\n",
    "print('dbgain: {}'.format(10*np.log10(F1)))\n",
    "\n",
    "bin_relative_index = f0 % F1\n",
    "\n",
    "w0 = (2*np.pi)*f0/N\n",
    "snrdb = 0\n",
    "\n",
    "num_correct = 0\n",
    "num_iter = 5000\n",
    "\n",
    "num_delays_per_chain = 3\n",
    "num_chains = 4\n",
    "\n",
    "total_samples = num_chains*num_delays_per_chain\n",
    "print('total samples: {}'.format(total_samples))\n",
    "\n",
    "for i in tqdm(range(num_iter)):\n",
    "    # successive estimation ----\n",
    "    A = make_kay_chains(w0,\n",
    "                        num_chains,\n",
    "                        num_delays_per_chain,\n",
    "                        snrdb+10*np.log10(F1))\n",
    "    \n",
    "    # the one used in ffast paper\n",
    "    r = successive_estimation(A,N,rounding=(bin_relative_index,F1))    \n",
    "    b = r\n",
    "    \n",
    "#     print(b)\n",
    "    \n",
    "    num_correct += (b == f0)\n",
    "    \n",
    "print('success: {}'.format(num_correct/num_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explorations to understand things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore dependent or independent sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "p = 3\n",
    "N = p**n\n",
    "f0 = 0\n",
    "w0 = (2*np.pi)*f0/N\n",
    "snrdb = -3\n",
    "num_iter = 5000\n",
    "\n",
    "\n",
    "num_chains = n\n",
    "\n",
    "\n",
    "pairs_per_chain = 8*p\n",
    "num_samples_per_pair = 2\n",
    "\n",
    "total_delays = pairs_per_chain*num_samples_per_pair\n",
    "\n",
    "sub_ml_numpairs = (pairs_per_chain*num_samples_per_pair)//p\n",
    "\n",
    "print('total dealys: {}'.format(total_delays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_to_bit(v,p):\n",
    "    return int(p*((np.angle(v*np.exp(1j*np.pi/p))/2/np.pi)%1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error = 0\n",
    "\n",
    "z_vec_indep = []\n",
    "for i in range(num_iter):\n",
    "    A,B = make_our_chains(w0=w0,\n",
    "                          n=num_chains,\n",
    "                          num_pairs_per_chain=pairs_per_chain,\n",
    "                          snrdb=snrdb,\n",
    "                          prime_base=p,\n",
    "                          num_samples_per_pair=num_samples_per_pair)\n",
    "    \n",
    "    \n",
    "    z = 0\n",
    "    c = 0\n",
    "\n",
    "    # go through only the first chain\n",
    "    for x in A[0]:\n",
    "        a,b = x\n",
    "        c +=1\n",
    "        z += b*np.conj(a)\n",
    "    z /= c\n",
    "    z_vec_indep.append(z)\n",
    "    total_error += np.abs(z-1)**2\n",
    "\n",
    "\n",
    "    \n",
    "preds = [value_to_bit(zi,p) for zi in z_vec_indep]\n",
    "print('wrong class: {0:.2f}%'.format(100*np.mean( np.array(preds) != f0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error = 0\n",
    "\n",
    "z_vec_dep = []\n",
    "\n",
    "for i in range(num_iter):\n",
    "    A,B = make_our_chains(w0=w0,\n",
    "                          n=num_chains,\n",
    "                          num_pairs_per_chain=1,\n",
    "                          snrdb=snrdb,\n",
    "                          prime_base=p,\n",
    "                          num_samples_per_pair=total_delays)\n",
    "    \n",
    "    z = 0\n",
    "    \n",
    "    x = np.array(A[0][0])\n",
    "    \n",
    "    c = len(x)-1\n",
    "    \n",
    "    phases_vec = np.array(x[1:])*np.conj(x[0:-1])\n",
    "    z = np.sum(phases_vec)/c\n",
    "    \n",
    "#     z = kay_weights(c+1).dot(phases_vec\n",
    "    \n",
    "    z_vec_dep.append(z)\n",
    "    \n",
    "    total_error +=np.abs(z - 1)**2\n",
    "\n",
    "preds = [value_to_bit(zi,p) for zi in z_vec_dep]\n",
    "print('wrong class: {0:.2f}%'.format(100*np.mean( np.array(preds) != f0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error = 0\n",
    "\n",
    "z_vec_ml = []\n",
    "\n",
    "for i in range(num_iter):\n",
    "    A,B = make_our_chains(w0=w0,\n",
    "                          n=num_chains,\n",
    "                          num_pairs_per_chain=1,\n",
    "                          snrdb=snrdb,\n",
    "                          prime_base=p,\n",
    "                          num_samples_per_pair=total_delays)\n",
    "    \n",
    "    r = our_method(A,\n",
    "                   B,\n",
    "                   prime_base=p,\n",
    "                   bin_estimator=estimate_bit_ml)\n",
    "    z = np.exp(1j*r)\n",
    "    \n",
    "    \n",
    "    z_vec_ml.append(z)\n",
    "    \n",
    "    total_error +=np.abs(z - 1)**2\n",
    "\n",
    "preds = [value_to_bit(zi,p) for zi in z_vec_ml]\n",
    "print('wrong class: {0:.2f}%'.format(100*np.mean( np.array(preds) != f0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error = 0\n",
    "\n",
    "z_vec_sub_ml = []\n",
    "\n",
    "print('num pairs: {}'.format(sub_ml_numpairs))\n",
    "\n",
    "new_estimator = lambda chain, sampling_points, ref_w0, prime_base: estimate_bit_sub_ml(chain,\n",
    "                        sampling_points,\n",
    "                        ref_w0,\n",
    "                        prime_base,\n",
    "                        summing_power=1)\n",
    "\n",
    "for i in range(num_iter):\n",
    "    A,B = make_our_chains(w0=w0,\n",
    "                          n=num_chains,\n",
    "                          num_pairs_per_chain=sub_ml_numpairs,\n",
    "                          snrdb=snrdb,\n",
    "                          prime_base=p,\n",
    "                          num_samples_per_pair=p)\n",
    "    \n",
    "    r = our_method(A,\n",
    "                   B,\n",
    "                   prime_base=p,\n",
    "                   bin_estimator=new_estimator)\n",
    "    z = np.exp(1j*r)\n",
    "    \n",
    "    \n",
    "    z_vec_sub_ml.append(z)\n",
    "    \n",
    "    total_error +=np.abs(z - 1)**2\n",
    "\n",
    "preds = [value_to_bit(zi,p) for zi in z_vec_sub_ml]\n",
    "print('wrong class: {0:.2f}%'.format(100*np.mean( np.array(preds) != f0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "\n",
    "num_delays_per_chain = num_pairs_per_chain*num_samples_per_pair\n",
    "\n",
    "print('total samples: {}'.format(num_delays_per_chain))\n",
    "\n",
    "z_vec_kay = []\n",
    "\n",
    "for i in tqdm(range(num_iter)):\n",
    "    # successive estimation ----\n",
    "    A = make_kay_chains(w0=w0,\n",
    "                        num_chains=num_chains,\n",
    "                        num_samples_per_chain=total_delays,\n",
    "                        snrdb=snrdb)\n",
    "    \n",
    "    # the one used in ffast paper\n",
    "    r = kays_method(A[0],simple_average=False)\n",
    "    \n",
    "    z_vec_kay.append( np.exp(1j*r) )    \n",
    "\n",
    "preds = [value_to_bit(zi,p) for zi in z_vec_kay]\n",
    "print('wrong class: {0:.2f}%'.format(100*np.mean( np.array(preds) != f0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "ax = plt.subplot(111, projection='polar')\n",
    "\n",
    "\n",
    "ax.scatter(np.angle(z_vec_indep),np.abs(z_vec_indep),label='indep',alpha=0.5)\n",
    "ax.scatter(np.angle(z_vec_dep),np.abs(z_vec_dep),label='dep',alpha=0.5)\n",
    "\n",
    "ax.scatter(np.angle(z_vec_kay),2*np.abs(z_vec_kay),label='kay',alpha=0.5,c='k')\n",
    "ax.scatter(np.angle(z_vec_ml), 4*np.abs(z_vec_ml), marker='s', s=100, label='ml', c='C5',alpha=1)\n",
    "\n",
    "\n",
    "ax.set_rticks([1, 2, 3, 4])  # less radial ticks\n",
    "ax.set_rlabel_position(-180/p)  # get radial labels away from plotted line\n",
    "\n",
    "ax.set_thetagrids(np.arange(0,2*p)*180/p)\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "plt.legend()\n",
    "plt.axvline(0,linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method with multiple factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing our method\n",
    "p1 = 2\n",
    "n1 = 2\n",
    "\n",
    "p2 = 3\n",
    "n2 = 2\n",
    "\n",
    "N = (p1**n1)*(p2**n2)\n",
    "\n",
    "f0 = 3\n",
    "w0 = (2*np.pi)*f0/N\n",
    "\n",
    "signal = np.exp(1j*w0*np.arange(N))\n",
    "\n",
    "num_pairs_per_chain = 1\n",
    "print(num_pairs_per_chain)\n",
    "\n",
    "num_correct = 0\n",
    "num_iter = 500\n",
    "\n",
    "# total_samples = n*2*num_pairs_per_chain\n",
    "# print('total samples: {}'.format(total_samples))\n",
    "\n",
    "\n",
    "# we want to find it with respect to p2\n",
    "B = make_our_locations(n2,1,p2,2,p1**n1)\n",
    "\n",
    "observation_matrix = []\n",
    "\n",
    "# go through each chain\n",
    "for chain in B:\n",
    "    print('chain')\n",
    "    # go through each delay\n",
    "    for d0,d1 in chain:\n",
    "        # downsample the signal\n",
    "        subsampling_locations = (int(d0) + np.arange(0,N,p2**n2)) % N\n",
    "        subsampled_signal = signal[subsampling_locations]\n",
    "        observation_matrix.append(np.fft.fft(subsampled_signal))\n",
    "        \n",
    "        subsampling_locations = (int(d1) + np.arange(0,N,p2**n2)) % N\n",
    "        subsampled_signal = signal[subsampling_locations]\n",
    "        observation_matrix.append(np.fft.fft(subsampled_signal))\n",
    "\n",
    "\n",
    "\n",
    "target_bin = f0 % (p1**n1)\n",
    "rotate = np.exp(1j*np.pi/p2)\n",
    "\n",
    "print(np.abs(observation_matrix[0][target_bin]))\n",
    "\n",
    "\n",
    "v1 = np.conj(observation_matrix[0][target_bin])*observation_matrix[1][target_bin]\n",
    "\n",
    "angle1 = np.angle(rotate*v1)/2/np.pi % 1\n",
    "a = int(angle1*p2) % p2\n",
    "\n",
    "v2 = np.conj(observation_matrix[2][target_bin])*observation_matrix[3][target_bin]\n",
    "v2 = v2*np.exp(-1j*2*np.pi*a/(p2**n2))\n",
    "\n",
    "angle2 = np.angle(rotate*v2)/2/np.pi % 1\n",
    "b = int(angle2*p2) % p2\n",
    "\n",
    "\n",
    "print('bit0: {}'.format(a))\n",
    "print('bit1: {}'.format(b))\n",
    "\n",
    "print('truth: {}'.format(f0%(p2**n2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mse(w0,N,snrdb,ITER):\n",
    "    signal = make_signal(w0,0,N)\n",
    "    mse = 0\n",
    "    sigma2 = get_sigma2_from_snrdb(snrdb)\n",
    "    for i in range(ITER):\n",
    "        noise = make_noise(sigma2, N)\n",
    "        noisy_signal = signal + noise    \n",
    "        w_est = kays_method(noisy_signal)\n",
    "        squared_error = (w_est - w0)**2\n",
    "        mse += squared_error/ITER\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# kay's plots\n",
    "w0 = 2*np.pi*0.05\n",
    "N  = 24\n",
    "\n",
    "mse = test_mse(w0, N, 10, 400)\n",
    "\n",
    "10*np.log10(1/mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculations for deriving bounds for Kay-like averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 0.5, 0.5],[0.5, 0, 0.5],[0.5,0.5,0]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.diag([1.5, -.5])\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.array([[2/np.sqrt(6),1/np.sqrt(6),1/np.sqrt(6)],[0,-1/np.sqrt(2),1/np.sqrt(2)]]).T\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.dot(Z).dot(U.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0,0.5],[0.5,0]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2, U2 = np.linalg.eig(A)\n",
    "Z2 = np.diag(Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U2.dot(Z2).dot(U2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,100)[:-1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "x = np.linspace(0,1/a,100)[:-1]\n",
    "z = [(1-3*u)/(1-u) for u in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bound on sqrt part\n",
    "a = 100\n",
    "x = np.linspace(0,1/a,100)[:-1]\n",
    "z = [1/np.sqrt(1-2*u) for u in x]\n",
    "y = [np.exp(u + 10*u**2) for u in x] \n",
    "\n",
    "plt.plot(x,z,label='truth')\n",
    "plt.plot(x,y,label='bound')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bound on new part\n",
    "alpha = 2\n",
    "\n",
    "a = 4*alpha\n",
    "x = np.linspace(0,1/a,100)[:-1]\n",
    "\n",
    "\n",
    "\n",
    "z = [(1-2*u*alpha)/(1-2*u) for u in x]\n",
    "y = [1-2*alpha*u for u in x] \n",
    "\n",
    "plt.plot(x,z,label='truth')\n",
    "plt.plot(x,y,label='bound')\n",
    "plt.axhline(1/2,linestyle='--',c='r')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -1\n",
    "A = np.array([[2,a,0],[a,2,a],[0,a,2]])\n",
    "print(A)\n",
    "              \n",
    "\n",
    "np.sum(np.linalg.inv(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -1\n",
    "A = np.array([[1,0],[0,1]])\n",
    "\n",
    "np.sum(np.linalg.inv(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_soft_max(u,l=1):\n",
    "    return np.sum(u*np.exp(l*u))/np.sum(np.exp(l*u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_soft_max(np.array([1,2,3.9,4]),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log((45276-44988)/32)/np.log(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bound on the mgf of non-central chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu2 = 20\n",
    "\n",
    "t = np.linspace(0,1/4,100)[:-1]\n",
    "\n",
    "log_mgf = mu2*t/(1-2*t) - 0.5*np.log(1-2*t) - t*(mu2+1)\n",
    "\n",
    "bound = (2+4*mu2)*(t**2)\n",
    "\n",
    "plt.plot(t, log_mgf, label='truth')\n",
    "plt.plot(t, bound, label='bound')\n",
    "plt.axvline(1/4, c='C2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,1/3,100)[1:-1]\n",
    "\n",
    "u = 4\n",
    "\n",
    "y = (1/(1-2*t) -1)\n",
    "yb = u*t\n",
    "\n",
    "plt.plot(t, y, label='truth')\n",
    "plt.plot(t, yb, label='bound')\n",
    "plt.axvline((u-2)/(2*u), c='C2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# expectation stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITER = 100000\n",
    "a = 0\n",
    "v = 0.1\n",
    "for i in range(ITER):\n",
    "    a += np.sqrt((v+np.random.randn())**2 + np.random.randn()**2)/ITER\n",
    "\n",
    "a - np.sqrt(np.pi/2)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.pi/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.exp(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tensorflow.constant(np.random.randn(3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def find_M(u, num_iter = 30):\n",
    "    below = np.log(1/u)\n",
    "    above = 1/u\n",
    "    \n",
    "    def f(x):\n",
    "        return x - np.log(x/u)\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        mid = 0.5*(above+below)\n",
    "        v = f(mid)\n",
    "        if v > 0:\n",
    "            above = mid\n",
    "        elif v < 0:\n",
    "            below = mid\n",
    "        else:\n",
    "            return mid\n",
    "    return above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, u):\n",
    "    return x - np.log(x/u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.5\n",
    "f(1.2, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(np.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = find_M(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a - np.log(a/0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.logspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.logspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.logspace(-5,-1,100,base=np.exp(1))\n",
    "# u = np.linspace(0,1/np.exp(1),400)[1:-1]\n",
    "M = find_M(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(u, M/np.log(1/u))\n",
    "# plt.plot(u, M - np.log(M/u))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/np.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,10)[1:-1]\n",
    "y1 = np.log(2*t+1)\n",
    "y2 = t\n",
    "plt.plot(t,y1,label='truth')\n",
    "plt.plot(t,y2,label='bound')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,1,100)[1:-1]\n",
    "y1 = t*np.log(t)+t\n",
    "plt.plot(t,y1,label='truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def fun(x, a):\n",
    "    return (x**2/a**2)/(1+x/a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.logspace(0,6,100)\n",
    "y = fun(t,1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(t,y)\n",
    "plt.grid()\n",
    "plt.axvline(1e3, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def fun2(x, a, b):\n",
    "    return x/a - np.log(x/b)\n",
    "\n",
    "@np.vectorize\n",
    "def fun2(x, a, b):\n",
    "    return x/a - np.log(x/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,100,100)\n",
    "a = 9\n",
    "b = 0.1\n",
    "y = fun2(t,a,b)\n",
    "\n",
    "min_val = 1 - np.log(a/b)\n",
    "\n",
    "plt.plot(t,y)\n",
    "plt.grid()\n",
    "plt.axvline(18*np.log(a/b), color='C1', linestyle='--')\n",
    "plt.axhline(min_val, color='C2', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
